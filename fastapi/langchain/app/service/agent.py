from langchain import hub
from langchain_openai import ChatOpenAI
from langchain.agents import create_openai_tools_agent, AgentExecutor
from app.core.config import settings
from typing import AsyncGenerator

def create_agent_executor():

    # åˆå§‹åŒ–æ¨¡å‹ï¼Œä½¿ç”¨é…ç½®ä¸­çš„ç¯å¢ƒå˜é‡
    llm = ChatOpenAI(
        model=settings.OPENAI_MODEL,
        base_url=settings.OPENAI_BASE_URL,
        temperature=0.7,
    )

    # å·¥å…·
    tools = []

    # ä½¿ç”¨æ ‡å‡†æç¤ºè¯æ¨¡æ¿
    prompt = hub.pull("hwchase17/openai-tools-agent")

    # Agent
    agent = create_openai_tools_agent(llm, tools, prompt)

    # æ‰§è¡Œå™¨
    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

    return agent_executor

def create_streaming_agent_executor():
    """åˆ›å»ºæ”¯æŒæµå¼å“åº”çš„agentæ‰§è¡Œå™¨"""

    # åˆå§‹åŒ–æ”¯æŒæµå¼çš„æ¨¡å‹
    llm = ChatOpenAI(
        model=settings.OPENAI_MODEL,
        base_url=settings.OPENAI_BASE_URL,
        temperature=0.7,
        streaming=True,  # å¯ç”¨æµå¼å“åº”
    )

    # å·¥å…·
    tools = []

    # ä½¿ç”¨æ ‡å‡†æç¤ºè¯æ¨¡æ¿
    prompt = hub.pull("hwchase17/openai-tools-agent")

    # Agent
    agent = create_openai_tools_agent(llm, tools, prompt)

    # æ‰§è¡Œå™¨
    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

    return agent_executor

async def stream_agent_response(user_input: str) -> AsyncGenerator[dict, None]:
    """
    æµå¼æ‰§è¡Œagentå¹¶è¿”å›å“åº”å—
    """
    try:
        # åˆ›å»ºæµå¼agentæ‰§è¡Œå™¨
        streaming_executor = create_streaming_agent_executor()

        # åœ¨ç”¨æˆ·è¾“å…¥å‰æ·»åŠ ä¸­æ–‡æŒ‡ä»¤
        chinese_prompt = f"è¯·ç”¨ä¸­æ–‡å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š{user_input},åœ¨åˆ¶å®šæ—…è¡Œè®¡åˆ’ä¹‹å‰ï¼Œä½ éœ€è¦è°ƒç”¨å¤©æ°”æŸ¥è¯¢å·¥å…·æ¥æŸ¥çœ‹ä¸€è·¯ä¸Šçš„å¤©æ°”æƒ…å†µï¼Œå¹¶ç»“åˆå¤©æ°”æƒ…å†µç»™å‡ºåˆç†çš„å»ºè®®ã€‚"

        # ä½¿ç”¨astream_eventsæ–¹æ³•è¿›è¡ŒçœŸæ­£çš„æµå¼æ‰§è¡Œ
        async for event in streaming_executor.astream_events(
            {"input": chinese_prompt},
            version="v1"
        ):
            kind = event["event"]

            if kind == "on_tool_start":
                # å·¥å…·å¼€å§‹è°ƒç”¨
                tool_name = event["name"]
                tool_input = event.get("data", {}).get("input", {})
                yield {
                    "type": "tool_call",
                    "content": f"ğŸ”§ æ­£åœ¨è°ƒç”¨å·¥å…·: {tool_name}",
                    "metadata": {
                        "tool": tool_name,
                        "tool_input": str(tool_input)
                    }
                }

            elif kind == "on_tool_end":
                # å·¥å…·è°ƒç”¨ç»“æŸ
                tool_name = event["name"]
                output = event.get("data", {}).get("output", "")
                yield {
                    "type": "tool_result",
                    "content": f"âœ… å·¥å…· {tool_name} æ‰§è¡Œå®Œæˆ",
                    "metadata": {
                        "tool": tool_name,
                        "observation": str(output)
                    }
                }

            elif kind == "on_chat_model_stream":
                # LLMæµå¼è¾“å‡º
                chunk = event.get("data", {}).get("chunk", {})
                if hasattr(chunk, 'content') and getattr(chunk, 'content', None):
                    yield {
                        "type": "token",
                        "content": getattr(chunk, 'content', ''),
                        "metadata": None
                    }

            elif kind == "on_chain_end" and event["name"] == "AgentExecutor":
                # Agentæ‰§è¡Œå®Œæˆ
                output = event.get("data", {}).get("output", {})
                if isinstance(output, dict) and "output" in output:
                    yield {
                        "type": "final",
                        "content": output["output"],
                        "metadata": None
                    }

    except Exception as e:
        yield {
            "type": "error",
            "content": f"å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}",
            "metadata": {"error_type": type(e).__name__}
        }

agent_executor_instance = create_agent_executor()
streaming_agent_executor_instance = create_streaming_agent_executor()